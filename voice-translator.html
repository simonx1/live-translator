<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <title>Real-Time Voice Capture</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #ffffff;
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            overflow-x: hidden;
        }

        .header {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(20px);
            padding: 20px;
            position: sticky;
            top: 0;
            z-index: 100;
            border-bottom: 1px solid rgba(255, 255, 255, 0.2);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }

        .language-selector {
            display: flex;
            gap: 15px;
            align-items: center;
            justify-content: center;
            flex-wrap: wrap;
        }

        .language-group {
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .language-label {
            font-size: 14px;
            color: rgba(255, 255, 255, 0.8);
            min-width: 50px;
            font-weight: 600;
        }

        select {
            background: rgba(255, 255, 255, 0.2);
            border: 2px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 12px 18px;
            border-radius: 12px;
            font-size: 16px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
        }

        select:hover {
            background: rgba(255, 255, 255, 0.25);
            border-color: rgba(255, 255, 255, 0.5);
            transform: translateY(-2px);
        }

        select:focus {
            outline: none;
            border-color: #4facfe;
            box-shadow: 0 0 0 4px rgba(79, 172, 254, 0.3);
        }

        .subtitle-area {
            flex: 1;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 60px 20px;
            min-height: 400px;
            position: relative;
        }

        .subtitle-container {
            text-align: center;
            max-width: 900px;
            width: 100%;
            animation: fadeIn 0.6s ease;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(20px);
            border-radius: 24px;
            padding: 40px;
            border: 1px solid rgba(255, 255, 255, 0.2);
            box-shadow: 0 16px 64px rgba(0, 0, 0, 0.1);
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .original-text {
            font-size: 20px;
            color: rgba(255, 255, 255, 0.7);
            margin-bottom: 20px;
            line-height: 1.5;
            font-style: italic;
        }

        .translated-text {
            font-size: 36px;
            font-weight: 700;
            line-height: 1.3;
            text-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
            background: linear-gradient(135deg, #ffffff 0%, #f0f0f0 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            min-height: 50px;
        }

        .control-area {
            padding: 40px 20px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(20px);
            border-top: 1px solid rgba(255, 255, 255, 0.2);
        }

        .controls-row {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 30px;
            flex-wrap: wrap;
        }

        .voice-controls {
            display: flex;
            gap: 15px;
            align-items: center;
        }

        .voice-toggle {
            background: rgba(255, 255, 255, 0.2);
            border: 2px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 12px 20px;
            border-radius: 12px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
        }

        .voice-toggle.active {
            background: rgba(79, 172, 254, 0.4);
            border-color: #4facfe;
            box-shadow: 0 4px 20px rgba(79, 172, 254, 0.3);
        }

        .voice-toggle:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }

        .control-button {
            width: 140px;
            height: 140px;
            border-radius: 50%;
            border: none;
            font-size: 20px;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.4s ease;
            margin: 0 auto;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
            box-shadow: 0 12px 40px rgba(0, 0, 0, 0.2);
        }

        .control-button.start {
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
            color: white;
        }

        .control-button.start:hover {
            transform: scale(1.1);
            box-shadow: 0 16px 50px rgba(79, 172, 254, 0.5);
        }

        .control-button.stop {
            background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%);
            color: white;
        }

        .control-button.stop:hover {
            transform: scale(1.1);
            box-shadow: 0 16px 50px rgba(255, 107, 107, 0.5);
        }

        .control-button.listening::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 100%;
            height: 100%;
            background: rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            animation: pulse 2s ease-out infinite;
        }

        @keyframes pulse {
            0% { transform: translate(-50%, -50%) scale(1); opacity: 1; }
            100% { transform: translate(-50%, -50%) scale(1.8); opacity: 0; }
        }

        .button-container {
            display: flex;
            justify-content: center;
            margin-bottom: 30px;
        }

        .status {
            text-align: center;
            font-size: 16px;
            color: rgba(255, 255, 255, 0.8);
            margin-top: 20px;
            min-height: 24px;
            font-weight: 500;
        }

        .conversation-log {
            max-height: 350px;
            overflow-y: auto;
            padding: 25px;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(20px);
            border-radius: 16px;
            margin: 25px;
            border: 1px solid rgba(255, 255, 255, 0.2);
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        }

        .conversation-entry {
            margin-bottom: 20px;
            padding: 20px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 12px;
            border-left: 4px solid #4facfe;
            transition: all 0.3s ease;
        }

        .conversation-entry:hover {
            background: rgba(255, 255, 255, 0.15);
            transform: translateX(5px);
        }

        .conversation-original {
            font-size: 14px;
            color: rgba(255, 255, 255, 0.7);
            margin-bottom: 8px;
            font-style: italic;
        }

        .conversation-translated {
            font-size: 18px;
            color: #ffffff;
            font-weight: 500;
        }

        .conversation-time {
            font-size: 12px;
            color: rgba(255, 255, 255, 0.5);
            margin-top: 8px;
        }

        .clear-log {
            background: rgba(255, 255, 255, 0.2);
            border: 2px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 12px 24px;
            border-radius: 12px;
            font-size: 14px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 0 25px 15px 25px;
            backdrop-filter: blur(10px);
        }

        .clear-log:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.2);
        }

        .switch-languages {
            background: rgba(255, 255, 255, 0.2);
            border: 2px solid rgba(255, 255, 255, 0.3);
            color: white;
            padding: 12px 16px;
            border-radius: 12px;
            font-size: 24px;
            cursor: pointer;
            transition: all 0.3s ease;
            backdrop-filter: blur(10px);
        }

        .switch-languages:hover {
            background: rgba(255, 255, 255, 0.3);
            transform: rotate(180deg) translateY(-2px);
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.2);
        }

        .error-message {
            background: rgba(255, 107, 107, 0.2);
            border: 2px solid rgba(255, 107, 107, 0.5);
            color: #ff6b6b;
            padding: 20px;
            border-radius: 12px;
            margin: 25px;
            text-align: center;
            font-weight: 600;
            backdrop-filter: blur(10px);
        }

        .mic-icon {
            font-size: 28px;
            margin-bottom: 5px;
        }

        .ai-thinking {
            animation: pulse-ai 1.5s ease-in-out infinite;
        }

        @keyframes pulse-ai {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.6; }
        }

        .model-loading {
            background: rgba(79, 172, 254, 0.2);
            border: 2px solid rgba(79, 172, 254, 0.5);
            color: #4facfe;
            padding: 20px;
            border-radius: 12px;
            margin: 25px;
            text-align: center;
            font-weight: 600;
            backdrop-filter: blur(10px);
            animation: pulse-ai 2s ease-in-out infinite;
        }

        .permission-prompt {
            background: rgba(79, 172, 254, 0.2);
            border: 2px solid rgba(79, 172, 254, 0.5);
            color: #4facfe;
            padding: 20px;
            border-radius: 12px;
            margin: 25px;
            text-align: center;
            font-weight: 600;
            backdrop-filter: blur(10px);
        }

        @media (max-width: 768px) {
            .translated-text {
                font-size: 28px;
            }
            
            .original-text {
                font-size: 18px;
            }
            
            .control-button {
                width: 120px;
                height: 120px;
                font-size: 18px;
            }

            .subtitle-container {
                padding: 30px 20px;
            }

            .controls-row {
                flex-direction: column;
                gap: 20px;
            }

            .voice-controls {
                flex-wrap: wrap;
                justify-content: center;
            }

            .voice-toggle {
                padding: 10px 16px;
                font-size: 12px;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <div class="language-selector">
            <div class="language-group">
                <span class="language-label">From:</span>
                <select id="sourceLang">
                    <option value="en-US">English (US)</option>
                    <option value="pl-PL" selected>Polish</option>
                    <option value="it-IT">Italian</option>
                    <option value="es-ES">Spanish</option>
                    <option value="fr-FR">French</option>
                    <option value="de-DE">German</option>
                    <option value="pt-PT">Portuguese</option>
                    <option value="ru-RU">Russian</option>
                    <option value="ja-JP">Japanese</option>
                    <option value="ko-KR">Korean</option>
                    <option value="zh-CN">Chinese</option>
                </select>
            </div>
            <button class="switch-languages" onclick="switchLanguages()" title="Switch languages">‚áÑ</button>
            <div class="language-group">
                <span class="language-label">To:</span>
                <select id="targetLang">
                    <option value="en-US" selected>English (US)</option>
                    <option value="pl-PL">Polish</option>
                    <option value="it-IT">Italian</option>
                    <option value="es-ES">Spanish</option>
                    <option value="fr-FR">French</option>
                    <option value="de-DE">German</option>
                    <option value="pt-PT">Portuguese</option>
                    <option value="ru-RU">Russian</option>
                    <option value="ja-JP">Japanese</option>
                    <option value="ko-KR">Korean</option>
                    <option value="zh-CN">Chinese</option>
                </select>
            </div>
        </div>
    </div>

    <div class="subtitle-area">
        <div class="subtitle-container" id="subtitleContainer">
            <div class="original-text" id="originalText">AI speech translation ‚Ä¢ Click microphone to record</div>
            <div class="translated-text" id="translatedText">
                AI speech translation loading...
            </div>
        </div>
    </div>

    <div class="control-area">
        <div class="controls-row">
            <button class="control-button start" id="controlButton" onclick="toggleListening()">
                <div class="mic-icon">üé§</div>
                <div>Start</div>
            </button>
            <div class="voice-controls">
                <button class="voice-toggle" id="autoSpeakToggle" onclick="toggleAutoSpeak()">
                    üîá Auto Speak
                </button>
                <button class="voice-toggle" id="manualSpeakButton" onclick="speakTranslation()">
                    ‚ñ∂Ô∏è Speak Text
                </button>
            </div>
        </div>
        <div class="status" id="status">Loading AI models...</div>
    </div>

    <button class="clear-log" onclick="clearLog()">üóëÔ∏è Clear Capture History</button>
    <div class="conversation-log" id="conversationLog"></div>

    <script type="module">
        let pipeline, env;
        
        try {
            console.log('üîß Loading Xenova/transformers library...');
            const transformers = await import('https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2/dist/transformers.min.js');
            pipeline = transformers.pipeline;
            env = transformers.env;
            console.log('‚úÖ Xenova/transformers library loaded successfully');
        } catch (error) {
            console.error('‚ùå Failed to load Xenova/transformers library:', error);
            document.getElementById('status').textContent = '‚ùå Failed to load AI library - please refresh the page';
            document.getElementById('translatedText').textContent = 'AI library failed to load. Please refresh the page or check your internet connection.';
        }
        
        // Define global functions FIRST for onclick handlers
        let recognition;
        let mediaRecorder;
        let audioChunks = [];
        let stream;
        let isListening = false;
        let currentTranscript = '';
        let translationTimeout;
        let conversationHistory = [];
        let finalTranscriptTimeout;
        let translator = null;
        let whisperModel = null;
        let isModelLoading = false;
        let autoSpeak = false;
        let lastSpokenText = '';
        let recordingTimeout;
        let chunkProcessingInterval;
        let isProcessingChunk = false;
        let chunkCounter = 0;

        // Voice language mapping for text-to-speech
        const voiceLanguageMap = {
            'en': 'en-US',
            'pl': 'pl-PL', 
            'it': 'it-IT',
            'es': 'es-ES',
            'fr': 'fr-FR',
            'de': 'de-DE',
            'pt': 'pt-PT',
            'ru': 'ru-RU',
            'ja': 'ja-JP',
            'ko': 'ko-KR',
            'zh': 'zh-CN'
        };

        // Language mapping for the translation model
        const languageMap = {
            'en': 'eng_Latn',
            'pl': 'pol_Latn', 
            'it': 'ita_Latn',
            'es': 'spa_Latn',
            'fr': 'fra_Latn',
            'de': 'deu_Latn',
            'pt': 'por_Latn',
            'ru': 'rus_Cyrl',
            'ja': 'jpn_Jpan',
            'ko': 'kor_Hang',
            'zh': 'zho_Hans'
        };

        // Make functions global for onclick handlers
        window.toggleListening = function() {
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        }

        window.toggleAutoSpeak = function() {
            autoSpeak = !autoSpeak;
            const button = document.getElementById('autoSpeakToggle');
            
            if (autoSpeak) {
                button.classList.add('active');
                button.textContent = 'üîä Auto Speak';
                updateStatus('üîä Auto-speak enabled');
            } else {
                button.classList.remove('active');
                button.textContent = 'üîá Auto Speak';
                updateStatus('üîá Auto-speak disabled');
                speechSynthesis.cancel(); // Stop any ongoing speech
            }
        }

        window.speakTranslation = function() {
            const translatedText = document.getElementById('translatedText').textContent;
            const targetLang = document.getElementById('targetLang').value.split('-')[0];
            
            if (translatedText && !translatedText.includes('Loading') && !translatedText.includes('Ready')) {
                speakText(translatedText, targetLang);
            } else {
                updateStatus('‚ö†Ô∏è No translation to speak');
            }
        }

        window.clearLog = function() {
            conversationHistory = [];
            updateConversationLog();
            updateStatus('üóëÔ∏è History cleared');
        }

        window.switchLanguages = function() {
            const sourceLang = document.getElementById('sourceLang');
            const targetLang = document.getElementById('targetLang');
            
            const temp = sourceLang.value;
            sourceLang.value = targetLang.value;
            targetLang.value = temp;
            
            updateStatus('üîÑ Languages switched');
        }

        function updateStatus(message) {
            const statusEl = document.getElementById('status');
            if (statusEl) {
                statusEl.textContent = message;
            }
        }

        function updateConversationLog() {
            const logContainer = document.getElementById('conversationLog');
            if (conversationHistory.length === 0) {
                logContainer.innerHTML = '<div style="text-align: center; color: rgba(255,255,255,0.6); font-style: italic;">Translation history will appear here</div>';
                return;
            }
            
            logContainer.innerHTML = conversationHistory.map(entry => `
                <div class="conversation-entry">
                    <div class="conversation-original">üó£Ô∏è ${entry.sourceLang.toUpperCase()}: ${entry.original}</div>
                    <div class="conversation-translated">ü§ñ ${entry.targetLang.toUpperCase()}: ${entry.translated}</div>
                    <div class="conversation-time">‚è∞ ${entry.timestamp.toLocaleTimeString()}</div>
                </div>
            `).join('');
        }

        // Text-to-Speech functions
        function speakText(text, language) {
            if (!text.trim()) return;
            
            // Cancel any ongoing speech
            speechSynthesis.cancel();
            
            const utterance = new SpeechSynthesisUtterance(text);
            const voiceLang = voiceLanguageMap[language] || 'en-US';
            
            // Try to find a voice for the target language
            const voices = speechSynthesis.getVoices();
            const targetVoice = voices.find(voice => 
                voice.lang.startsWith(language) || voice.lang === voiceLang
            );
            
            if (targetVoice) {
                utterance.voice = targetVoice;
            }
            
            utterance.lang = voiceLang;
            utterance.rate = 0.9; // Slightly slower for clarity
            utterance.pitch = 1.0;
            utterance.volume = 1.0;
            
            utterance.onstart = () => {
                updateStatus('üîä Speaking translation...');
            };
            
            utterance.onend = () => {
                updateStatus(isListening ? 'üé§ Listening... Speak now!' : '‚úÖ Ready');
            };
            
            utterance.onerror = (event) => {
                console.error('Speech synthesis error:', event.error);
                updateStatus('‚ö†Ô∏è Speech synthesis failed');
            };
            
            speechSynthesis.speak(utterance);
        }

        // Initialize models
        async function initModels() {
            if ((translator && whisperModel) || isModelLoading) return { translator, whisperModel };
            
            // Check if pipeline is available
            if (!pipeline || !env) {
                console.error('‚ùå Xenova/transformers library not loaded');
                showError('AI library not loaded. Please refresh the page.');
                updateStatus('‚ùå AI library not loaded');
                return { translator: null, whisperModel: null };
            }
            
            isModelLoading = true;
            showModelLoading();
            updateStatus('ü§ñ Loading AI models... (this may take a moment)');
            
            try {
                console.log('ü§ñ Starting model initialization...');
                
                // Configure environment for remote model loading
                env.allowRemoteModels = true;
                env.allowLocalModels = false;
                
                console.log('ü§ñ Environment configured, loading models...');
                
                // Choose the best speech model for your needs:
                // Option 1: Moonshine (fastest, ~75ms latency, English only)
                // Option 2: Distil-Whisper (6x faster than Whisper, multilingual)
                // Option 3: Whisper-tiny (smallest, multilingual, slower)
                
                const speechModelOptions = {
                    'moonshine': 'onnx-community/moonshine-base-ONNX',     // Fastest (English only)
                    'distil': 'distil-whisper/distil-large-v2',           // 6x faster, multilingual (verified working)
                    'whisper-tiny': 'Xenova/whisper-tiny',                // Smallest, multilingual
                    'whisper-base': 'Xenova/whisper-base'                 // Original (slower)
                };
                
                console.log('ü§ñ Loading translation model - checking device capabilities...');
                
                // Check if mobile device and use smaller model
                const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
                const isLowMemory = navigator.deviceMemory && navigator.deviceMemory < 4; // Less than 4GB RAM
                
                let translationModel;
                if (isMobile || isLowMemory) {
                    console.log('ü§ñ Mobile/low-memory device detected, using lighter model...');
                    try {
                        // Try smaller model first for mobile
                        translationModel = 'Xenova/nllb-200-distilled-1.3B';
                        translator = await pipeline('translation', translationModel);
                    } catch (error) {
                        console.log('ü§ñ Fallback: Using even smaller model for mobile...');
                        translationModel = 'Xenova/opus-mt-mul-en'; // Much smaller multilingual model
                        translator = await pipeline('translation', translationModel);
                    }
                } else {
                    console.log('ü§ñ Desktop device detected, using full model...');
                    translationModel = 'Xenova/nllb-200-distilled-600M';
                    translator = await pipeline('translation', translationModel);
                }
                
                whisperModel = 'web-speech-api'; // Always use Web Speech API
                console.log('ü§ñ Using translation model:', translationModel);
                
                
                console.log('ü§ñ Models loaded successfully!');
                hideModelLoading();
                updateStatus('‚úÖ AI models loaded! Ready for speech translation.');
                return { translator, whisperModel };
            } catch (error) {
                console.error('Model loading error:', error);
                console.error('Error details:', error.message);
                console.error('Error stack:', error.stack);
                hideModelLoading();
                
                // Mobile fallback: try speech recognition only mode
                console.log('üîÑ Translation model failed, trying speech-only mode for mobile...');
                try {
                    translator = 'no-translation'; // Marker for speech-only mode
                    whisperModel = 'web-speech-api';
                    updateStatus('‚ö†Ô∏è Speech recognition only - translation unavailable on this device');
                    showError('Translation model failed to load. Using speech recognition only.');
                    return { translator, whisperModel };
                } catch (fallbackError) {
                    console.error('Complete fallback failed:', fallbackError);
                }
                
                showError(`AI models failed to load: ${error.message}. Speech recognition may still work.`);
                updateStatus('‚ùå AI translation unavailable - speech recognition only');
                translator = 'no-translation';
                whisperModel = 'web-speech-api';
                return { translator, whisperModel };
            } finally {
                isModelLoading = false;
            }
        }

        // Initialize audio recording for Whisper
        async function initAudioRecording() {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                // Try different audio formats for better compatibility
                let mimeType;
                if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
                    mimeType = 'audio/webm;codecs=opus';
                } else if (MediaRecorder.isTypeSupported('audio/mp4')) {
                    mimeType = 'audio/mp4';
                } else {
                    mimeType = 'audio/webm';
                }
                
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: mimeType,
                    audioBitsPerSecond: 128000
                });
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    // Process final chunk when stopped
                    if (audioChunks.length > 0) {
                        processAudioWithWhisper(true); // true = final chunk
                    }
                };
                
                return true;
            } catch (error) {
                console.error('Failed to initialize audio recording:', error);
                showError('Microphone access denied or not available. Please allow microphone access and refresh.');
                return false;
            }
        }
        
        // Process recorded audio with Whisper (streaming)
        async function processAudioWithWhisper(isFinal = false) {
            console.log('üé§ processAudioWithWhisper called, isFinal:', isFinal, 'audioChunks:', audioChunks.length, 'isProcessingChunk:', isProcessingChunk);
            
            if (!whisperModel || audioChunks.length === 0 || isProcessingChunk) {
                console.log('üé§ Skipping processing - whisperModel:', !!whisperModel, 'audioChunks:', audioChunks.length, 'isProcessingChunk:', isProcessingChunk);
                return;
            }
            
            isProcessingChunk = true;
            
            try {
                if (!isFinal) {
                    updateStatus('ü§ñ Processing speech... (keep talking)');
                } else {
                    updateStatus('ü§ñ Processing final speech...');
                }
                
                // Combine audio chunks into a blob
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                console.log('üé§ Created audio blob, size:', audioBlob.size, 'bytes');
                
                // Don't clear chunks unless it's the final processing
                if (isFinal) {
                    audioChunks = [];
                }
                
                // Create URL for the blob
                const audioUrl = URL.createObjectURL(audioBlob);
                console.log('üé§ Created audio URL:', audioUrl);
                
                // Get source language for Whisper
                const sourceLang = document.getElementById('sourceLang').value.split('-')[0];
                console.log('üé§ Source language:', sourceLang);
                
                // Map language codes to Whisper's expected format
                const whisperLanguageMap = {
                    'en': 'english',
                    'pl': 'polish',
                    'it': 'italian', 
                    'es': 'spanish',
                    'fr': 'french',
                    'de': 'german',
                    'pt': 'portuguese',
                    'ru': 'russian',
                    'ja': 'japanese',
                    'ko': 'korean',
                    'zh': 'chinese'
                };
                
                const whisperLang = whisperLanguageMap[sourceLang] || 'english';
                console.log('üé§ Whisper language:', whisperLang);
                
                // Process with Whisper using the audio URL - fast processing
                console.log('üé§ Starting Whisper processing...');
                const result = await whisperModel(audioUrl, {
                    language: whisperLang,
                    return_timestamps: false,
                    chunk_length_s: 15,
                    stride_length_s: 2,
                    num_beams: 1,
                    temperature: 0.0
                });
                
                // Clean up the object URL
                URL.revokeObjectURL(audioUrl);
                
                const transcript = result.text.trim();
                console.log('üé§ Whisper result:', result);
                console.log('üé§ Whisper transcript (chunk):', transcript);
                
                if (transcript && transcript.length > 2) { // Lower threshold for faster response
                    console.log('üé§ Valid transcript, updating UI and translating...');
                    document.getElementById('originalText').textContent = transcript;
                    currentTranscript = transcript;
                    
                    // Translate immediately for real-time feel (no debouncing for speed)
                    translateText(transcript, isFinal); // Only save to history on final
                    
                    // Update status based on whether we're still recording
                    if (isListening && !isFinal) {
                        updateStatus('üé§ Listening... (real-time processing)');
                    }
                } else if (isFinal) {
                    console.log('üé§ No valid transcript found');
                    document.getElementById('originalText').textContent = 'No clear speech detected';
                    updateStatus('üîá No clear speech detected. Try speaking louder.');
                }
                
            } catch (error) {
                console.error('Whisper processing error:', error);
                console.error('Error details:', error.message);
                console.error('Error stack:', error.stack);
                if (isFinal) {
                    document.getElementById('originalText').textContent = 'Speech processing failed';
                    updateStatus('‚ùå Speech processing failed');
                }
            } finally {
                isProcessingChunk = false;
            }
        }
        
        // Process audio chunks periodically while recording
        function startChunkProcessing() {
            chunkProcessingInterval = setInterval(() => {
                if (isListening && !isProcessingChunk && audioChunks.length >= 3) {
                    // Process accumulated chunks so far (need at least 3 chunks for good results)
                    processAudioWithWhisper(false); // false = intermediate chunk
                }
            }, 1500); // Process every 1.5 seconds for fast but stable response
        }
        
        function stopChunkProcessing() {
            if (chunkProcessingInterval) {
                clearInterval(chunkProcessingInterval);
                chunkProcessingInterval = null;
            }
        }

        async function startListening() {
            console.log('üé§ Start button clicked');
            console.log('ü§ñ Translator loaded:', !!translator);
            console.log('ü§ñ Using Web Speech API for recognition');
            
            if (!translator) {
                console.error('‚ùå Translation model not ready');
                showError('AI translation model not loaded. Please wait for it to load or refresh the page.');
                updateStatus('‚ùå Translation model not ready');
                return;
            }
            
            // Use Web Speech API instead of audio recording
            if (!initWebSpeechRecognition()) {
                return;
            }
            
            const sourceLang = document.getElementById('sourceLang').value;
            recognition.lang = sourceLang;
            
            try {
                recognition.start();
                isListening = true;
                
                const button = document.getElementById('controlButton');
                button.innerHTML = '<div class="mic-icon">üõë</div><div>Stop</div>';
                button.classList.remove('start');
                button.classList.add('stop', 'listening');
                
                document.getElementById('originalText').textContent = 'Listening...';
                document.getElementById('translatedText').textContent = 'Speak now for real-time translation';
                
                updateStatus('üé§ Listening... Speak now!');
                
            } catch (e) {
                console.error('Failed to start recognition:', e);
                showError('üö´ Failed to start voice recognition. Please ensure microphone access is allowed.');
            }
        }
        
        // Initialize Web Speech Recognition (fast and reliable)
        function initWebSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                showError('Voice recognition is not supported in this browser. Please use Chrome, Edge, or Safari.');
                return false;
            }

            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.maxAlternatives = 1;
            
            recognition.onstart = () => {
                console.log('üé§ Web Speech recognition started');
                updateStatus('üé§ Listening... Speak now!');
            };

            recognition.onresult = (event) => {
                let interimTranscript = '';
                let finalTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }

                // Update display with current speech
                const displayText = finalTranscript || interimTranscript;
                if (displayText.trim()) {
                    document.getElementById('originalText').textContent = displayText;
                    
                    // Clear previous timeout
                    clearTimeout(translationTimeout);
                    
                    // Translate with short delay for real-time feel
                    translationTimeout = setTimeout(() => {
                        currentTranscript = displayText;
                        translateText(displayText, !!finalTranscript); // Save to history only if final
                    }, 300);
                }
            };

            recognition.onerror = (event) => {
                console.error('üö´ Speech recognition error:', event.error);
                if (event.error === 'not-allowed') {
                    showError('üö´ Microphone access denied. Please allow microphone access and refresh the page.');
                } else if (event.error === 'no-speech') {
                    updateStatus('üîá No speech detected. Try speaking louder.');
                } else {
                    updateStatus(`‚ùå Error: ${event.error}. Please try again.`);
                }
                
                if (event.error === 'not-allowed' || event.error === 'audio-capture') {
                    stopListening();
                }
            };

            recognition.onend = () => {
                console.log('üîö Speech recognition ended');
                if (isListening) {
                    // Auto-restart recognition if still listening
                    setTimeout(() => {
                        try {
                            recognition.start();
                        } catch (e) {
                            console.error('Failed to restart recognition:', e);
                            updateStatus('‚ö†Ô∏è Connection lost. Click Start to resume.');
                            stopListening();
                        }
                    }, 100);
                }
            };

            return true;
        }

        function stopListening() {
            if (recognition) {
                recognition.stop();
            }
            
            isListening = false;
            
            // Cancel any ongoing speech
            speechSynthesis.cancel();
            
            const button = document.getElementById('controlButton');
            button.innerHTML = '<div class="mic-icon">üé§</div><div>Start</div>';
            button.classList.remove('stop', 'listening');
            button.classList.add('start');
            
            updateStatus('üîá Voice recognition stopped');
            
            // Clear timeouts
            clearTimeout(translationTimeout);
            clearTimeout(finalTranscriptTimeout);
        }

        async function translateText(text, saveToHistory = true) {
            if (!text.trim()) return;
            
            const sourceLang = document.getElementById('sourceLang').value.split('-')[0];
            const targetLang = document.getElementById('targetLang').value.split('-')[0];
            
            // Handle no-translation mode (mobile fallback)
            if (!translator || translator === 'no-translation') {
                document.getElementById('translatedText').textContent = `[${sourceLang.toUpperCase()}] ${text}`;
                if (saveToHistory) {
                    addToHistory(text, `[Speech Recognition Only] ${text}`, sourceLang, sourceLang);
                }
                updateStatus(isListening ? 'üé§ Listening... (speech recognition only)' : '‚úÖ Speech captured (no translation)');
                return;
            }
            
            // Skip translation if source and target are the same
            if (sourceLang === targetLang) {
                document.getElementById('translatedText').textContent = text;
                if (saveToHistory) {
                    addToHistory(text, text, sourceLang, targetLang);
                }
                return;
            }
            
            updateStatus('ü§ñ Translating...');
            
            // Add visual thinking indicator
            const translatedElement = document.getElementById('translatedText');
            translatedElement.classList.add('ai-thinking');
            
            try {
                // Use AI model
                const srcLang = languageMap[sourceLang] || 'eng_Latn';
                const tgtLang = languageMap[targetLang] || 'eng_Latn';
                
                const result = await translator(text, {
                    src_lang: srcLang,
                    tgt_lang: tgtLang,
                    max_length: 100,  // Shorter max length for faster processing
                    num_beams: 1,     // Greedy decoding for speed
                    early_stopping: true
                });
                
                const translatedText = result[0].translation_text;
                
                document.getElementById('translatedText').textContent = translatedText;
                document.getElementById('translatedText').classList.remove('ai-thinking');
                
                // Add to conversation history (only for final translations)
                if (saveToHistory) {
                    addToHistory(text, translatedText, sourceLang, targetLang);
                }
                
                // Auto-speak the translation if enabled and it's a final result
                if (autoSpeak && saveToHistory && translatedText !== lastSpokenText) {
                    speakText(translatedText, targetLang);
                    lastSpokenText = translatedText;
                }
                
                updateStatus(isListening ? 'üé§ Listening... Speak now!' : '‚úÖ AI translation complete');
                
            } catch (error) {
                console.error('Translation error:', error);
                document.getElementById('translatedText').textContent = '‚ùå Translation failed';
                document.getElementById('translatedText').classList.remove('ai-thinking');
                updateStatus('‚ùå Translation error occurred');
            }
        }

        function addToHistory(original, translated, sourceLang, targetLang) {
            // Avoid duplicate entries
            const lastEntry = conversationHistory[0];
            if (lastEntry && lastEntry.original === original && lastEntry.translated === translated) {
                return;
            }
            
            const entry = {
                original,
                translated,
                sourceLang,
                targetLang,
                timestamp: new Date()
            };
            
            conversationHistory.unshift(entry);
            
            // Limit history to 50 entries
            if (conversationHistory.length > 50) {
                conversationHistory = conversationHistory.slice(0, 50);
            }
            
            updateConversationLog();
        }

        function showError(message) {
            const errorDiv = document.createElement('div');
            errorDiv.className = 'error-message';
            errorDiv.innerHTML = `‚ùå ${message}`;
            document.body.insertBefore(errorDiv, document.querySelector('.conversation-log'));
            
            setTimeout(() => {
                if (errorDiv.parentNode) {
                    errorDiv.remove();
                }
            }, 8000);
        }

        function showModelLoading() {
            const loadingDiv = document.createElement('div');
            loadingDiv.className = 'model-loading';
            loadingDiv.id = 'modelLoading';
            loadingDiv.innerHTML = `
                ü§ñ <strong>Loading AI Translation Model</strong><br>
                This may take a moment on first load...
            `;
            document.body.insertBefore(loadingDiv, document.querySelector('.conversation-log'));
        }

        function hideModelLoading() {
            const loadingDiv = document.getElementById('modelLoading');
            if (loadingDiv) {
                loadingDiv.remove();
            }
        }

        function showPermissionPrompt() {
            const promptDiv = document.createElement('div');
            promptDiv.className = 'permission-prompt';
            promptDiv.innerHTML = `
                üé§ <strong>Microphone Access Required</strong><br>
                Please allow microphone access when prompted to enable voice translation.
            `;
            document.body.insertBefore(promptDiv, document.querySelector('.conversation-log'));
            
            setTimeout(() => {
                if (promptDiv.parentNode) {
                    promptDiv.remove();
                }
            }, 5000);
        }

        // Prevent same language selection
        document.getElementById('sourceLang').addEventListener('change', (e) => {
            const targetSelect = document.getElementById('targetLang');
            if (e.target.value === targetSelect.value) {
                const options = Array.from(targetSelect.options);
                const availableOption = options.find(opt => opt.value !== e.target.value);
                if (availableOption) {
                    targetSelect.value = availableOption.value;
                }
            }
        });

        document.getElementById('targetLang').addEventListener('change', (e) => {
            const sourceSelect = document.getElementById('sourceLang');
            if (e.target.value === sourceSelect.value) {
                const options = Array.from(sourceSelect.options);
                const availableOption = options.find(opt => opt.value !== e.target.value);
                if (availableOption) {
                    sourceSelect.value = availableOption.value;
                }
            }
        });

        // Initialize on load
        window.addEventListener('load', async () => {
            updateConversationLog();
            
            // Initialize speech synthesis voices
            if ('speechSynthesis' in window) {
                // Load voices
                speechSynthesis.getVoices();
                speechSynthesis.onvoiceschanged = () => {
                    console.log('üó£Ô∏è Speech synthesis voices loaded');
                };
            }
            
            // Wait a moment for the library to load if needed
            let retryCount = 0;
            const maxRetries = 10;
            
            while ((!pipeline || !env) && retryCount < maxRetries) {
                console.log(`‚è≥ Waiting for Xenova/transformers library to load... (attempt ${retryCount + 1}/${maxRetries})`);
                await new Promise(resolve => setTimeout(resolve, 1000));
                retryCount++;
            }
            
            if (!pipeline || !env) {
                console.error('‚ùå Xenova/transformers library failed to load after waiting');
                document.getElementById('translatedText').textContent = 'AI library failed to load. Please refresh the page.';
                updateStatus('‚ùå AI library failed to load');
                return;
            }
            
            // Set initial ready state
            document.getElementById('translatedText').textContent = 'Loading AI models...';
            updateStatus('ü§ñ Loading AI models...');
            
            // Initialize AI models
            await initModels();
            
            if (translator && whisperModel) {
                document.getElementById('translatedText').textContent = 'AI speech translation ready';
                updateStatus('üé§ Ready! Click Start to record and translate speech');
            }
            
            // Check for microphone support
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                showPermissionPrompt();
                
                // Pre-request microphone permission
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then((stream) => {
                        console.log('‚úÖ Microphone access granted');
                        if (translator && whisperModel) {
                            updateStatus('üé§ Ready! Click Start to record and translate speech');
                        }
                        
                        // Stop the stream since we just needed permission
                        stream.getTracks().forEach(track => track.stop());
                    })
                    .catch((err) => {
                        console.error('‚ùå Microphone access denied:', err);
                        showError('Microphone access is required for voice capture. Please allow access and refresh the page.');
                        updateStatus('‚ùå Microphone access denied');
                    });
            } else {
                showError('Your browser does not support microphone access. Please use Chrome, Edge, or Safari.');
            }
        });

        // Handle page visibility changes
        document.addEventListener('visibilitychange', () => {
            if (document.hidden && isListening) {
                console.log('‚è∏Ô∏è Page hidden, stopping recognition');
                stopListening();
            }
        });

        // Handle beforeunload to clean up
        window.addEventListener('beforeunload', () => {
            if (isListening) {
                stopListening();
            }
        });
    </script>
</body>
</html>